<!DOCTYPE html><!--FWdrmPigl_6Zt7TQsWf42--><html lang="en" class="scroll-smooth"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" href="/_next/static/media/0acc7fdf55eb3220-s.p.532ccaa1.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" href="/_next/static/media/83afe278b6a6bb3c-s.p.3a6ba036.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="stylesheet" href="/_next/static/chunks/f2a3ea31c3425353.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/7262920b81433816.js"/><script src="/_next/static/chunks/82abf2d65f5428ae.js" async=""></script><script src="/_next/static/chunks/dde2c8e6322d1671.js" async=""></script><script src="/_next/static/chunks/98e4389ba5c320ef.js" async=""></script><script src="/_next/static/chunks/turbopack-f891497d6add88c3.js" async=""></script><script src="/_next/static/chunks/ff1a16fafef87110.js" async=""></script><script src="/_next/static/chunks/d2be314c3ece3fbe.js" async=""></script><script src="/_next/static/chunks/60f4d6d62331baa7.js" async=""></script><script src="/_next/static/chunks/2383faa1982b04db.js" async=""></script><script src="/_next/static/chunks/fc07566903636968.js" async=""></script><meta name="next-size-adjust" content=""/><title>Aniket Verma | Senior Software Engineer</title><meta name="description" content="Senior Software Engineer Portfolio - AI/ML"/><link rel="icon" href="/favicon.ico?favicon.0b3bf435.ico" sizes="256x256" type="image/x-icon"/><script src="/_next/static/chunks/a6dad97d9634a72d.js" noModule=""></script></head><body class="inter_5901b7c6-module__ec5Qua__variable orbitron_dd03e8de-module__CVN8Yq__variable font-sans antialiased bg-slate-950 text-slate-200 selection:bg-cyan-500/30 selection:text-cyan-200"><div hidden=""><!--$--><!--/$--></div><main class="min-h-screen bg-slate-950 text-slate-200"><nav class="fixed top-0 w-full z-50 transition-all duration-300 bg-transparent py-4"><div class="container mx-auto px-4 flex justify-between items-center"><a class="flex items-center gap-2 group" href="/"><div class="relative"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-shield w-8 h-8 text-cyan-500 group-hover:text-cyan-400 transition-colors" aria-hidden="true"><path d="M20 13c0 5-3.5 7.5-7.66 8.95a1 1 0 0 1-.67-.01C7.5 20.5 4 18 4 13V6a1 1 0 0 1 1-1c2 0 4.5-1.2 6.24-2.72a1.17 1.17 0 0 1 1.52 0C14.51 3.81 17 5 19 5a1 1 0 0 1 1 1z"></path></svg><div class="absolute inset-0 bg-cyan-500/20 blur-lg rounded-full group-hover:bg-cyan-400/30 transition-all"></div></div><span class="font-orbitron font-bold text-xl tracking-wider text-slate-100 group-hover:text-cyan-400 transition-colors">AV<span class="text-cyan-500">.hq</span></span></a><div class="hidden md:flex items-center gap-8"><a class="text-sm font-medium text-slate-400 hover:text-cyan-400 transition-colors uppercase tracking-widest relative group" href="/#hero">Mission<span class="absolute -bottom-1 left-0 w-0 h-0.5 bg-cyan-500 transition-all duration-300 group-hover:w-full"></span></a><a class="text-sm font-medium text-slate-400 hover:text-cyan-400 transition-colors uppercase tracking-widest relative group" href="/#skills">Skills<span class="absolute -bottom-1 left-0 w-0 h-0.5 bg-cyan-500 transition-all duration-300 group-hover:w-full"></span></a><a class="text-sm font-medium text-slate-400 hover:text-cyan-400 transition-colors uppercase tracking-widest relative group" href="/#experience">Journey<span class="absolute -bottom-1 left-0 w-0 h-0.5 bg-cyan-500 transition-all duration-300 group-hover:w-full"></span></a><a class="text-sm font-medium text-slate-400 hover:text-cyan-400 transition-colors uppercase tracking-widest relative group" href="/#projects">Projects<span class="absolute -bottom-1 left-0 w-0 h-0.5 bg-cyan-500 transition-all duration-300 group-hover:w-full"></span></a><a class="text-sm font-medium text-slate-400 hover:text-cyan-400 transition-colors uppercase tracking-widest relative group" href="/blog">Blog<span class="absolute -bottom-1 left-0 w-0 h-0.5 bg-cyan-500 transition-all duration-300 group-hover:w-full"></span></a><a class="text-sm font-medium text-slate-400 hover:text-cyan-400 transition-colors uppercase tracking-widest relative group" href="/#achievements">Impact<span class="absolute -bottom-1 left-0 w-0 h-0.5 bg-cyan-500 transition-all duration-300 group-hover:w-full"></span></a><a class="text-sm font-medium text-slate-400 hover:text-cyan-400 transition-colors uppercase tracking-widest relative group" href="/#about">About<span class="absolute -bottom-1 left-0 w-0 h-0.5 bg-cyan-500 transition-all duration-300 group-hover:w-full"></span></a><a class="text-sm font-medium text-slate-400 hover:text-cyan-400 transition-colors uppercase tracking-widest relative group" href="/#contact">Contact<span class="absolute -bottom-1 left-0 w-0 h-0.5 bg-cyan-500 transition-all duration-300 group-hover:w-full"></span></a><a class="px-6 py-2 bg-cyan-500/10 border border-cyan-500/50 text-cyan-400 font-bold uppercase tracking-wider text-xs rounded hover:bg-cyan-500 hover:text-black transition-all duration-300 shadow-[0_0_10px_rgba(6,182,212,0.2)] hover:shadow-[0_0_20px_rgba(6,182,212,0.6)]" href="#contact">initiate_comms</a></div><button class="md:hidden text-slate-200 hover:text-cyan-400 transition-colors"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-menu w-8 h-8" aria-hidden="true"><path d="M4 5h16"></path><path d="M4 12h16"></path><path d="M4 19h16"></path></svg></button></div></nav><div class="fixed inset-0 -z-10"><div class="absolute inset-0 bg-gradient-to-b from-slate-950 via-slate-900 to-slate-950 opacity-50"></div><div class="absolute top-1/4 left-1/4 w-96 h-96 bg-cyan-500/10 rounded-full blur-3xl"></div><div class="absolute bottom-1/4 right-1/4 w-96 h-96 bg-blue-500/10 rounded-full blur-3xl"></div></div><article class="max-w-4xl mx-auto px-4 py-24"><button class="inline-flex items-center gap-2 text-cyan-400 hover:text-cyan-300 mb-8 transition-colors group"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-arrow-left w-5 h-5 group-hover:-translate-x-1 transition-transform" aria-hidden="true"><path d="m12 19-7-7 7-7"></path><path d="M19 12H5"></path></svg>Back to Blog</button><span class="inline-block px-4 py-2 bg-cyan-500/20 text-cyan-400 text-sm font-semibold rounded-full mb-6">Technology</span><h1 class="text-5xl md:text-6xl font-bold text-white mb-6 font-[family-name:var(--font-orbitron)] leading-tight">How I fine-tune a Large Language Model (LLM) — practical steps you can use today</h1><p class="text-xl text-slate-400 mb-8 leading-relaxed">How I fine-tune a Large Language Model (LLM) — practical steps you can use today</p><div class="flex flex-wrap items-center gap-6 text-sm text-slate-400 mb-8 pb-8 border-b border-slate-800"><span class="flex items-center gap-2"><svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-calendar" aria-hidden="true"><path d="M8 2v4"></path><path d="M16 2v4"></path><rect width="18" height="18" x="3" y="4" rx="2"></rect><path d="M3 10h18"></path></svg>January 31, 2026</span><span class="flex items-center gap-2"><svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-clock" aria-hidden="true"><path d="M12 6v6l4 2"></path><circle cx="12" cy="12" r="10"></circle></svg>5<!-- --> min read</span><span class="flex items-center gap-2"><svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-eye" aria-hidden="true"><path d="M2.062 12.348a1 1 0 0 1 0-.696 10.75 10.75 0 0 1 19.876 0 1 1 0 0 1 0 .696 10.75 10.75 0 0 1-19.876 0"></path><circle cx="12" cy="12" r="3"></circle></svg>6<!-- --> views</span><span class="text-cyan-400 font-medium">By <!-- -->Aniket Verma</span></div><div class="flex flex-wrap gap-3 mb-8"><span class="inline-flex items-center gap-2 px-4 py-2 glass text-cyan-400 text-sm rounded-lg hover:bg-cyan-500/10 transition-colors"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-tag" aria-hidden="true"><path d="M12.586 2.586A2 2 0 0 0 11.172 2H4a2 2 0 0 0-2 2v7.172a2 2 0 0 0 .586 1.414l8.704 8.704a2.426 2.426 0 0 0 3.42 0l6.58-6.58a2.426 2.426 0 0 0 0-3.42z"></path><circle cx="7.5" cy="7.5" r=".5" fill="currentColor"></circle></svg>Python</span><span class="inline-flex items-center gap-2 px-4 py-2 glass text-cyan-400 text-sm rounded-lg hover:bg-cyan-500/10 transition-colors"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-tag" aria-hidden="true"><path d="M12.586 2.586A2 2 0 0 0 11.172 2H4a2 2 0 0 0-2 2v7.172a2 2 0 0 0 .586 1.414l8.704 8.704a2.426 2.426 0 0 0 3.42 0l6.58-6.58a2.426 2.426 0 0 0 0-3.42z"></path><circle cx="7.5" cy="7.5" r=".5" fill="currentColor"></circle></svg>Langchain</span><span class="inline-flex items-center gap-2 px-4 py-2 glass text-cyan-400 text-sm rounded-lg hover:bg-cyan-500/10 transition-colors"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-tag" aria-hidden="true"><path d="M12.586 2.586A2 2 0 0 0 11.172 2H4a2 2 0 0 0-2 2v7.172a2 2 0 0 0 .586 1.414l8.704 8.704a2.426 2.426 0 0 0 3.42 0l6.58-6.58a2.426 2.426 0 0 0 0-3.42z"></path><circle cx="7.5" cy="7.5" r=".5" fill="currentColor"></circle></svg>LLM</span></div><div class="blog-content text-lg"><p>Want to get better performance from an LLM without reinventing the wheel? Here&rsquo;s a clear, practical workflow I use to fine-tune models &mdash; useful for prod prototypes, domain-adapted agents, or custom assistants.</p>

<p>TL;DR: collect clean domain data &rarr; choose a base model &amp; approach (full-finetune vs LoRA/PEFT) &rarr; preprocess &amp; format prompts &rarr; train with smart hyperparams &rarr; validate + safety checks &rarr; deploy &amp; monitor.</p>

<p>1) Start with a clear goal</p>

<p>What do you want the model to do differently? (e.g., medical Q&amp;A tone, summarise lab reports, code review assistant). Define success metrics &mdash; accuracy, helpfulness, fewer hallucinations, or reduced latency.</p>

<p>2) Data: quality &gt; quantity</p>

<p>Gather representative datasets: user logs, manuals, expert answers, annotated examples.</p>

<p>Clean it: remove PII, fix formatting, normalize units, dedupe.</p>

<p>Prefer high-quality few-shot examples over huge noisy corpora.</p>

<p>Structure data for the training objective: instruction&ndash;response pairs for instruction tuning, (prompt, completion) for supervised finetuning.</p>

<p>3) Choose the right tuning strategy</p>

<p>Full finetuning: best when you can afford compute and want maximal performance. More risk of catastrophic forgetting.</p>

<p>LoRA / PEFT (parameter-efficient finetuning): change a tiny fraction of weights &mdash; much cheaper, faster, and easy to revert. Great default for production.</p>

<p>Prompt tuning / adapters: even lighter-weight options for resource constrained setups.</p>

<p>Consider instruction tuning if you want generalized instruction-following, or supervised finetuning if you have lots of curated Q&rarr;A pairs.</p>

<p>4) Prompt &amp; tokenization design</p>

<p>Use consistent instruction templates (system prompt, user prompt, expected response).</p>

<p>Verify tokenization &mdash; long domain docs might hit context limits. Trim or chunk wisely (sliding windows or hierarchical summarization).</p>

<p>5) Training best practices</p>

<p>Use mixed precision (fp16/bf16) to speed up and reduce memory.</p>

<p>Start with small learning rates; PEFT typically uses lower LR than full finetuning.</p>

<p>Use gradient accumulation for large batches if GPU memory is limited.</p>

<p>Monitor loss and qualitative outputs &mdash; loss alone can be misleading.</p>

<p>Use early stopping and keep checkpoints.</p>

<p>6) Evaluation &mdash; automatic + human</p>

<p>Build validation sets that match real usage.</p>

<p>Use automated metrics (BLEU/ROUGE for generation is weak), but focus on task-specific metrics (accuracy, F1, intent correctness).</p>

<p>Add human review for quality, alignment, and safety &mdash; sample outputs across failure modes.</p>

<p>Test for hallucinations by crafting adversarial prompts.</p>

<p>7) Safety, privacy &amp; legal</p>

<p>Remove or redact PII before training.</p>

<p>Add guardrails: a separate safety classifier or instruction-following constraints.</p>

<p>Keep a rollback plan &mdash; track which weights are changed and be able to revert to base model.</p>

<p>8) Deployment &amp; monitoring</p>

<p>Package model with versioned artifacts (model + tokenizer + config).</p>

<p>Serve via a scalable endpoint (FastAPI/Gunicorn, or managed infra).</p>

<p>Monitor latency, error rates, drift in input distribution, and user feedback.</p>

<p>Retrain/correct iteratively &mdash; collect failure examples and incorporate them into next round.</p>

<p>9) Cost &amp; infra considerations</p>

<p>PEFT + quantization (8-bit) lowers serving cost and makes edge deployment possible.</p>

<p>Use spot instances for training if you can tolerate interruptions.</p>

<p>Measure cost per query vs benefit &mdash; sometimes clever prompting + retrieval augmentation beats heavy finetuning.</p>

<p>10) Iterate</p>

<p>Fine-tuning is not a one-shot job. Use real user interactions, telemetry, and evaluation to prioritize the next round of data collection and model updates.</p></div><div class="mt-12 pt-8 border-t border-slate-800"><button class="px-8 py-3 bg-gradient-to-r from-cyan-500 to-blue-600 text-white font-semibold rounded-lg hover:shadow-lg hover:shadow-cyan-500/50 transition-all duration-300">Read More Articles</button></div></article><footer class="py-8 bg-slate-950 border-t border-slate-900 text-center relative z-10"><div class="container mx-auto px-4"><p class="text-slate-500 font-mono text-sm">© <!-- -->2026<!-- --> Aniket Verma. All Systems Operational.</p><p class="text-slate-600 text-xs mt-2 uppercase tracking-widest">Designed with Avengers Initiative Protocol</p></div></footer></main><!--$--><!--/$--><div class="fixed bottom-6 right-6 md:bottom-8 md:right-8 z-[100] flex flex-col items-end gap-2"><div class="relative bg-black/80 border border-cyan-500/50 text-cyan-400 px-3 py-2 rounded-lg backdrop-blur-md shadow-[0_0_15px_rgba(34,211,238,0.2)] mb-2 max-w-[180px] md:max-w-[200px]" style="opacity:0;transform:translateY(10px) scale(0.9)"><p class="text-xs md:text-sm font-mono typing-cursor"></p><div class="absolute -bottom-2 right-4 w-3 h-3 md:w-4 md:h-4 bg-black/80 border-r border-b border-cyan-500/50 transform rotate-45"></div></div><button class="bg-cyan-500/20 hover:bg-cyan-500/40 text-cyan-400 border border-cyan-500/50 rounded-full p-3 md:p-4 shadow-[0_0_20px_rgba(34,211,238,0.3)] backdrop-blur-md transition-all group" style="opacity:0;transform:scale(0)"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-cpu w-6 h-6 md:w-8 md:h-8 group-hover:rotate-180 transition-transform duration-700" aria-hidden="true"><path d="M12 20v2"></path><path d="M12 2v2"></path><path d="M17 20v2"></path><path d="M17 2v2"></path><path d="M2 12h2"></path><path d="M2 17h2"></path><path d="M2 7h2"></path><path d="M20 12h2"></path><path d="M20 17h2"></path><path d="M20 7h2"></path><path d="M7 20v2"></path><path d="M7 2v2"></path><rect x="4" y="4" width="16" height="16" rx="2"></rect><rect x="8" y="8" width="8" height="8" rx="1"></rect></svg></button></div><script src="/_next/static/chunks/7262920b81433816.js" id="_R_" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n2:I[39756,[\"/_next/static/chunks/ff1a16fafef87110.js\",\"/_next/static/chunks/d2be314c3ece3fbe.js\"],\"default\"]\n3:I[37457,[\"/_next/static/chunks/ff1a16fafef87110.js\",\"/_next/static/chunks/d2be314c3ece3fbe.js\"],\"default\"]\n4:I[94074,[\"/_next/static/chunks/60f4d6d62331baa7.js\",\"/_next/static/chunks/2383faa1982b04db.js\"],\"default\"]\n6:I[97367,[\"/_next/static/chunks/ff1a16fafef87110.js\",\"/_next/static/chunks/d2be314c3ece3fbe.js\"],\"OutletBoundary\"]\n7:\"$Sreact.suspense\"\n9:I[97367,[\"/_next/static/chunks/ff1a16fafef87110.js\",\"/_next/static/chunks/d2be314c3ece3fbe.js\"],\"ViewportBoundary\"]\nb:I[97367,[\"/_next/static/chunks/ff1a16fafef87110.js\",\"/_next/static/chunks/d2be314c3ece3fbe.js\"],\"MetadataBoundary\"]\nd:I[68027,[],\"default\"]\n:HL[\"/_next/static/chunks/f2a3ea31c3425353.css\",\"style\"]\n:HL[\"/_next/static/media/0acc7fdf55eb3220-s.p.532ccaa1.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"/_next/static/media/83afe278b6a6bb3c-s.p.3a6ba036.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"FWdrmPigl-6Zt7TQsWf42\",\"c\":[\"\",\"blog\",\"how-i-fine-tune-a-large-language-model-llm-practical-steps-you-can-use-today\"],\"q\":\"\",\"i\":false,\"f\":[[[\"\",{\"children\":[\"blog\",{\"children\":[[\"slug\",\"how-i-fine-tune-a-large-language-model-llm-practical-steps-you-can-use-today\",\"d\"],{\"children\":[\"__PAGE__\",{}]}]}]},\"$undefined\",\"$undefined\",true],[[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/chunks/f2a3ea31c3425353.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}],[\"$\",\"script\",\"script-0\",{\"src\":\"/_next/static/chunks/60f4d6d62331baa7.js\",\"async\":true,\"nonce\":\"$undefined\"}],[\"$\",\"script\",\"script-1\",{\"src\":\"/_next/static/chunks/2383faa1982b04db.js\",\"async\":true,\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"en\",\"className\":\"scroll-smooth\",\"children\":[\"$\",\"body\",null,{\"className\":\"inter_5901b7c6-module__ec5Qua__variable orbitron_dd03e8de-module__CVN8Yq__variable font-sans antialiased bg-slate-950 text-slate-200 selection:bg-cyan-500/30 selection:text-cyan-200\",\"children\":[[\"$\",\"$L2\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L3\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":404}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],[]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}],[\"$\",\"$L4\",null,{}]]}]}]]}],{\"children\":[[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L2\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L3\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L2\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L3\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[[\"$\",\"$1\",\"c\",{\"children\":[\"$L5\",[[\"$\",\"script\",\"script-0\",{\"src\":\"/_next/static/chunks/fc07566903636968.js\",\"async\":true,\"nonce\":\"$undefined\"}]],[\"$\",\"$L6\",null,{\"children\":[\"$\",\"$7\",null,{\"name\":\"Next.MetadataOutlet\",\"children\":\"$@8\"}]}]]}],{},null,false,false]},null,false,false]},null,false,false]},null,false,false],[\"$\",\"$1\",\"h\",{\"children\":[null,[\"$\",\"$L9\",null,{\"children\":\"$La\"}],[\"$\",\"div\",null,{\"hidden\":true,\"children\":[\"$\",\"$Lb\",null,{\"children\":[\"$\",\"$7\",null,{\"name\":\"Next.Metadata\",\"children\":\"$Lc\"}]}]}],[\"$\",\"meta\",null,{\"name\":\"next-size-adjust\",\"content\":\"\"}]]}],false]],\"m\":\"$undefined\",\"G\":[\"$d\",[]],\"S\":true}\n"])</script><script>self.__next_f.push([1,"a:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"meta\",\"1\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\n"])</script><script>self.__next_f.push([1,"e:I[27201,[\"/_next/static/chunks/ff1a16fafef87110.js\",\"/_next/static/chunks/d2be314c3ece3fbe.js\"],\"IconMark\"]\n8:null\nc:[[\"$\",\"title\",\"0\",{\"children\":\"Aniket Verma | Senior Software Engineer\"}],[\"$\",\"meta\",\"1\",{\"name\":\"description\",\"content\":\"Senior Software Engineer Portfolio - AI/ML\"}],[\"$\",\"link\",\"2\",{\"rel\":\"icon\",\"href\":\"/favicon.ico?favicon.0b3bf435.ico\",\"sizes\":\"256x256\",\"type\":\"image/x-icon\"}],[\"$\",\"$Le\",\"3\",{}]]\n"])</script><script>self.__next_f.push([1,"f:I[74021,[\"/_next/static/chunks/60f4d6d62331baa7.js\",\"/_next/static/chunks/2383faa1982b04db.js\",\"/_next/static/chunks/fc07566903636968.js\"],\"default\"]\n11:T1022,"])</script><script>self.__next_f.push([1,"\u003cp\u003eWant to get better performance from an LLM without reinventing the wheel? Here\u0026rsquo;s a clear, practical workflow I use to fine-tune models \u0026mdash; useful for prod prototypes, domain-adapted agents, or custom assistants.\u003c/p\u003e\r\n\r\n\u003cp\u003eTL;DR: collect clean domain data \u0026rarr; choose a base model \u0026amp; approach (full-finetune vs LoRA/PEFT) \u0026rarr; preprocess \u0026amp; format prompts \u0026rarr; train with smart hyperparams \u0026rarr; validate + safety checks \u0026rarr; deploy \u0026amp; monitor.\u003c/p\u003e\r\n\r\n\u003cp\u003e1) Start with a clear goal\u003c/p\u003e\r\n\r\n\u003cp\u003eWhat do you want the model to do differently? (e.g., medical Q\u0026amp;A tone, summarise lab reports, code review assistant). Define success metrics \u0026mdash; accuracy, helpfulness, fewer hallucinations, or reduced latency.\u003c/p\u003e\r\n\r\n\u003cp\u003e2) Data: quality \u0026gt; quantity\u003c/p\u003e\r\n\r\n\u003cp\u003eGather representative datasets: user logs, manuals, expert answers, annotated examples.\u003c/p\u003e\r\n\r\n\u003cp\u003eClean it: remove PII, fix formatting, normalize units, dedupe.\u003c/p\u003e\r\n\r\n\u003cp\u003ePrefer high-quality few-shot examples over huge noisy corpora.\u003c/p\u003e\r\n\r\n\u003cp\u003eStructure data for the training objective: instruction\u0026ndash;response pairs for instruction tuning, (prompt, completion) for supervised finetuning.\u003c/p\u003e\r\n\r\n\u003cp\u003e3) Choose the right tuning strategy\u003c/p\u003e\r\n\r\n\u003cp\u003eFull finetuning: best when you can afford compute and want maximal performance. More risk of catastrophic forgetting.\u003c/p\u003e\r\n\r\n\u003cp\u003eLoRA / PEFT (parameter-efficient finetuning): change a tiny fraction of weights \u0026mdash; much cheaper, faster, and easy to revert. Great default for production.\u003c/p\u003e\r\n\r\n\u003cp\u003ePrompt tuning / adapters: even lighter-weight options for resource constrained setups.\u003c/p\u003e\r\n\r\n\u003cp\u003eConsider instruction tuning if you want generalized instruction-following, or supervised finetuning if you have lots of curated Q\u0026rarr;A pairs.\u003c/p\u003e\r\n\r\n\u003cp\u003e4) Prompt \u0026amp; tokenization design\u003c/p\u003e\r\n\r\n\u003cp\u003eUse consistent instruction templates (system prompt, user prompt, expected response).\u003c/p\u003e\r\n\r\n\u003cp\u003eVerify tokenization \u0026mdash; long domain docs might hit context limits. Trim or chunk wisely (sliding windows or hierarchical summarization).\u003c/p\u003e\r\n\r\n\u003cp\u003e5) Training best practices\u003c/p\u003e\r\n\r\n\u003cp\u003eUse mixed precision (fp16/bf16) to speed up and reduce memory.\u003c/p\u003e\r\n\r\n\u003cp\u003eStart with small learning rates; PEFT typically uses lower LR than full finetuning.\u003c/p\u003e\r\n\r\n\u003cp\u003eUse gradient accumulation for large batches if GPU memory is limited.\u003c/p\u003e\r\n\r\n\u003cp\u003eMonitor loss and qualitative outputs \u0026mdash; loss alone can be misleading.\u003c/p\u003e\r\n\r\n\u003cp\u003eUse early stopping and keep checkpoints.\u003c/p\u003e\r\n\r\n\u003cp\u003e6) Evaluation \u0026mdash; automatic + human\u003c/p\u003e\r\n\r\n\u003cp\u003eBuild validation sets that match real usage.\u003c/p\u003e\r\n\r\n\u003cp\u003eUse automated metrics (BLEU/ROUGE for generation is weak), but focus on task-specific metrics (accuracy, F1, intent correctness).\u003c/p\u003e\r\n\r\n\u003cp\u003eAdd human review for quality, alignment, and safety \u0026mdash; sample outputs across failure modes.\u003c/p\u003e\r\n\r\n\u003cp\u003eTest for hallucinations by crafting adversarial prompts.\u003c/p\u003e\r\n\r\n\u003cp\u003e7) Safety, privacy \u0026amp; legal\u003c/p\u003e\r\n\r\n\u003cp\u003eRemove or redact PII before training.\u003c/p\u003e\r\n\r\n\u003cp\u003eAdd guardrails: a separate safety classifier or instruction-following constraints.\u003c/p\u003e\r\n\r\n\u003cp\u003eKeep a rollback plan \u0026mdash; track which weights are changed and be able to revert to base model.\u003c/p\u003e\r\n\r\n\u003cp\u003e8) Deployment \u0026amp; monitoring\u003c/p\u003e\r\n\r\n\u003cp\u003ePackage model with versioned artifacts (model + tokenizer + config).\u003c/p\u003e\r\n\r\n\u003cp\u003eServe via a scalable endpoint (FastAPI/Gunicorn, or managed infra).\u003c/p\u003e\r\n\r\n\u003cp\u003eMonitor latency, error rates, drift in input distribution, and user feedback.\u003c/p\u003e\r\n\r\n\u003cp\u003eRetrain/correct iteratively \u0026mdash; collect failure examples and incorporate them into next round.\u003c/p\u003e\r\n\r\n\u003cp\u003e9) Cost \u0026amp; infra considerations\u003c/p\u003e\r\n\r\n\u003cp\u003ePEFT + quantization (8-bit) lowers serving cost and makes edge deployment possible.\u003c/p\u003e\r\n\r\n\u003cp\u003eUse spot instances for training if you can tolerate interruptions.\u003c/p\u003e\r\n\r\n\u003cp\u003eMeasure cost per query vs benefit \u0026mdash; sometimes clever prompting + retrieval augmentation beats heavy finetuning.\u003c/p\u003e\r\n\r\n\u003cp\u003e10) Iterate\u003c/p\u003e\r\n\r\n\u003cp\u003eFine-tuning is not a one-shot job. Use real user interactions, telemetry, and evaluation to prioritize the next round of data collection and model updates.\u003c/p\u003e"])</script><script>self.__next_f.push([1,"5:[\"$\",\"$Lf\",null,{\"params\":\"$@10\",\"initialPost\":{\"id\":1,\"title\":\"How I fine-tune a Large Language Model (LLM) — practical steps you can use today\",\"slug\":\"how-i-fine-tune-a-large-language-model-llm-practical-steps-you-can-use-today\",\"excerpt\":\"How I fine-tune a Large Language Model (LLM) — practical steps you can use today\",\"content\":\"$11\",\"featured_image_url\":null,\"author\":\"Aniket Verma\",\"category\":\"Technology\",\"tags\":[\"Python\",\"Langchain\",\"LLM\"],\"read_time\":5,\"views\":6,\"created_at\":\"2026-01-31T12:02:35.591662Z\",\"updated_at\":\"2026-01-31T12:02:35.591674Z\",\"published_at\":\"2026-01-31T12:00:52Z\",\"meta_description\":\"How I fine-tune a Large Language Model (LLM) — practical steps you can use today\",\"meta_keywords\":\"\"}}]\n"])</script><script>self.__next_f.push([1,"10:{\"slug\":\"how-i-fine-tune-a-large-language-model-llm-practical-steps-you-can-use-today\"}\n"])</script></body></html>